{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### The University of Melbourne, School of Computing and Information Systems\n",
    "# COMP30027 Machine Learning, 2020 Semester 1\n",
    "\n",
    "## Assignment 1: Naive Bayes Classifiers\n",
    "\n",
    "###### Submission deadline: 7 pm, Monday 20 Apr 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Student Name(s):**    Andy Chen, Miow Fong Sim\n",
    "\n",
    "**Student ID(s):**     903370, 881623"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This iPython notebook is a template which you will use for your Assignment 1 submission.\n",
    "\n",
    "Marking will be applied on the four functions that are defined in this notebook, and to your responses to the questions at the end of this notebook (Submitted in a separate PDF file).\n",
    "\n",
    "**NOTE: YOU SHOULD ADD YOUR RESULTS, DIAGRAMS AND IMAGES FROM YOUR OBSERVATIONS IN THIS FILE TO YOUR REPORT (the PDF file).**\n",
    "\n",
    "You may change the prototypes of these functions, and you may write other functions, according to your requirements. We would appreciate it if the required functions were prominent/easy to find.\n",
    "\n",
    "**Adding proper comments to your code is MANDATORY. **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For pre-processing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# For smoothing\n",
    "from collections import defaultdict\n",
    "\n",
    "# For Gaussian pdf\n",
    "import scipy.stats as stats\n",
    "\n",
    "# For train/test split\n",
    "import random\n",
    "\n",
    "# For visualisation\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "###GIVEN DATASETS###\n",
    "\n",
    "f1 = 'breast-cancer-wisconsin.data'\n",
    "a1 = 'Sample code number,Clump Thickness,Uniformity of Cell Size,Uniformity of Cell Shape,Marginal Adhesion,Single Epithelial Cell Size,Bare Nuclei,Bland Chromatin,Normal Nucleoli,Mitoses,class'.split(',')\n",
    "\n",
    "f2 = 'mushroom.data'\n",
    "a2 = 'class,cap-shape,cap-surface,cap-color,bruises?,odor,gill-attachment,gil-spacing,gill-size,gill-color,stalk-shape,stalk-root,stalk-surface-above-ring,stalk-surface-below-ring,stalk-color-above-ring,stalk-color-below-ring,veil-type,veil-color,ring-number,ring-type,spore-print-color,population,habitat'.split(',')\n",
    "\n",
    "f3 = 'lymphography.data'\n",
    "a3 = 'class,lymphatics,block of affere,bl. of lymph. c,bl. of lymph. s,by pass,extravasates,regeneration of,early uptake in,lym.nodes dimin,lym.nodes enlar,changes in lym.,defect in node,changes in node,changes in stru,special forms,dislocation of,exclusion of no,no. of nodes in'.split(',')\n",
    "\n",
    "f4 = 'wdbc.data'\n",
    "a4 = 'ID number,class,Mean radius,Mean texture,Mean perimeter,Mean area,Mean smoothness,Mean compactness,Mean concavity,Mean concave points,Mean symmetry,Mean fractal dimension,Radius SE,Texture SE,Perimeter SE,Area SE,Smoothness SE,Compactness SE,Concavity SE,Concave points SE,Symmetry SE,Fractal dimension SE,Worst radius,Worst texture,Worst perimeter,Worst area,Worst smoothness,Worst compactness,Worst concavity,Worst concave points,Worst symmetry,Worst fractal dimension'.split(',')\n",
    "\n",
    "f5 = 'wine.data'\n",
    "a5 = 'class,Alcohol,Malic acid,Ash,Alcalinity of ash,Magnesium,Total phenols,Flavanoids,Nonflavanoid phenols,Proanthocyanins,Color intensity,Hue,OD280/OD315 of diluted wines,Proline'.split(',')\n",
    "\n",
    "f6 = 'car.data'\n",
    "a6 = 'buying,maint,doors,persons,lug_boot,safety,class'.split(',')\n",
    "\n",
    "f7 = 'nursery.data'\n",
    "a7 = 'parents,has_nurs,form,children,housing,finance,social,health,class'.split(',')\n",
    "\n",
    "f8 = 'somerville.data'\n",
    "a8 = 'class,city information availability,housing cost,public schools overall quality,trust in the local police,streets and sidewalks maintenance,social community events availability'.split(',')\n",
    "\n",
    "f9 = 'adult.data'\n",
    "a9 = 'age,workclass,fnlwgt,education,education-num,marital-status,occupation,relationship,race,sex,capital-gain,capital-loss,hours-per-week,native-country,class'.split(',')\n",
    "\n",
    "f10 = 'bank.data'\n",
    "a10 = 'age,job,marital,education,default,balance,housing,loan,contact,day,campaign,pdays,previous,poutcome,class'.split(',')\n",
    "\n",
    "#Since there is no pre-defined class, let expenses be the class.\n",
    "f11 = 'university.data'\n",
    "a11 = 'University-name,State,Control,number-of-students,male:female (ratio),student:faculty (ratio),sat-verbal,sat-math,expenses,percent-financial-aid,number-of-applicants,percent-admittance,percent-enrolled,academics,social,quality-of-life,academic-emphasis'.split(',')\n",
    "\n",
    "### DATASETS DICTIONARY ###\n",
    "data = [f1,f2,f3,f4,f5,f6,f7,f8,f9,f10,f11]\n",
    "data_attributes = [a1,a2,a3,a4,a5,a6,a7,a8,a9,a10,a11]\n",
    "\n",
    "datasets_dictionary = {}\n",
    "for i in range(len(data)):\n",
    "    datasets_dictionary.update({data[i] : data_attributes[i]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function should prepare the data by reading it from a file and converting it into a useful format for training and testing\n",
    "\n",
    "#dataframe is created\n",
    "#missing values are replaced with NaN\n",
    "\n",
    "def preprocess(filename, cross_validation = False):\n",
    "    '''\n",
    "    Creates dataframe, replacing missing values\n",
    "    \n",
    "    Returns:\n",
    "        - dataframe, if 10-fold cross validation is not performed\n",
    "        - cross_val_dict, if 10-fold cross validation is performed  \n",
    "    '''\n",
    "    # Import file\n",
    "    dataframe = pd.read_csv(filename,encoding = 'ISO-8859-1', header = None, names = datasets_dictionary[filename])\n",
    "    \n",
    "    # Fix missing values\n",
    "    if filename == f11:\n",
    "        dataframe.replace('0', np.NaN, inplace=True)\n",
    "        print(dataframe.shape[0] - dataframe.dropna().shape[0], 'missing values found.')\n",
    "        \n",
    "    else:\n",
    "        dataframe.replace('?', np.NaN, inplace=True)\n",
    "        print(dataframe.shape[0] - dataframe.dropna().shape[0], 'missing values found.')\n",
    "    \n",
    "    # No cross validation\n",
    "    if cross_validation == False:\n",
    "        return dataframe\n",
    "    \n",
    "    # Cross validation\n",
    "    else:\n",
    "    \n",
    "    ############### QUESTION 4: 10- FOLD CROSS VALIDATION ###############\n",
    "    \n",
    "        # Split data into 10 parts and store partitions in a list\n",
    "        cross_val_parts = np.array_split(dataframe, 10)\n",
    "\n",
    "        # 1st partition will be testing set\n",
    "        # 2nd - 10th will be training set\n",
    "        # 2nd partition will be testing set \n",
    "        # 1st, 3rd- 10th partitions will be training set \n",
    "        # ...\n",
    "    \n",
    "        # Initialising keys to cross_val_dict\n",
    "        cross_val_dict = {'training': [], 'testing': []}\n",
    "    \n",
    "        k = 10\n",
    "        \n",
    "        for i in range(k):\n",
    "            \n",
    "            # cross_val_testing\n",
    "            cross_val_testing = cross_val_parts[i]\n",
    "            \n",
    "            # cross_val_training\n",
    "            left_training = cross_val_parts[:i]\n",
    "            right_training = cross_val_parts[i+1:]\n",
    "            \n",
    "            cross_val_training = pd.concat(left_training + right_training)\n",
    "\n",
    "            cross_val_dict['training'].append(cross_val_training)\n",
    "            cross_val_dict['testing'].append(cross_val_testing)\n",
    "        \n",
    "        return cross_val_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function should calculat prior probabilities and likelihoods from the training data and using\n",
    "# them to build a naive Bayes model\n",
    "\n",
    "def train(data, smooth = (None, 0)):\n",
    "    '''\n",
    "    Calculates prior probabilities and likelihoods from training data.\n",
    "    \n",
    "    Arguments:\n",
    "        data: dataFrame\n",
    "            - rows are instances\n",
    "            - columns are attributes / class label\n",
    "            - instances with missing values have been omitted\n",
    "        smooth: tuple with dictionary assocating attribute to number of unique values and a smoothing parameter (Laplace)\n",
    "    \n",
    "    Returns: \n",
    "        Model, a single dictionary containing all necessary values for the naive-bayes classifier.\n",
    "    '''\n",
    "    \n",
    "    Model = {}\n",
    "    \n",
    "    for classlabel in data['class'].unique():\n",
    "        \n",
    "        # Stores priors and likelihoods for a class\n",
    "        Model[classlabel] = {}\n",
    "        \n",
    "        # Select all values of a single class, excluding the class column\n",
    "        class_data = data[data['class'] == classlabel].drop('class', axis=1)\n",
    "        \n",
    "        # Calculate prior probability of the class label\n",
    "        Model[classlabel]['prior'] = np.log(class_data.shape[0])-np.log(data.shape[0]) \n",
    "        \n",
    "        # Note: Log probabilities are used to prevent problems associated with underflow\n",
    "        \n",
    "        # Calculate likelihood of data: P(attribute=x|c)\n",
    "        Model[classlabel]['likelihood'] = {}\n",
    "        \n",
    "        for attribute in class_data.columns:\n",
    "            \n",
    "            # Numeric attribute which requires Gaussian pdf\n",
    "            # Note: isNumericAttribute is a dataset-specific function to identify continuous attributes.\n",
    "            if isNumericAttribute(class_data[attribute]):\n",
    "                \n",
    "                mu = class_data[attribute].mean()\n",
    "                sig = class_data[attribute].std()\n",
    "                assert(sig>0)\n",
    "                \n",
    "                # Store the mean and std of the distribution\n",
    "                Model[classlabel]['likelihood'][attribute] = (mu, sig)\n",
    "            \n",
    "            # Nominal/binned data which uses relative frequencies\n",
    "            else:\n",
    "                # Smoothing: retrieve number of unique values for the attribute\n",
    "                numUniqueValues = smooth[0][attribute]\n",
    "                smoothingparameter = smooth[1]\n",
    "                \n",
    "                # If smoothing paramters is 0, do not smooth\n",
    "                if smoothingparameter == 0:\n",
    "                    \n",
    "                    # Default probability close to 0, to avoid infinity.\n",
    "                    likelihood_attribute = defaultdict(lambda: np.log(10**(-24))) \n",
    "                    \n",
    "                    # Calculate relative frequency as an estimate to the likelihood\n",
    "                    for unique_value in class_data[attribute].unique():\n",
    "                        likelihood_attribute[unique_value] = np.log(sum(class_data[attribute] == unique_value))\\\n",
    "                        -np.log(class_data.shape[0])\n",
    "                    \n",
    "                # If smoothing parameter > 0. do add-k smoothing\n",
    "                else:\n",
    "                    \n",
    "                    # Default value is set to k /(N + k*d), where d = num. possible values and N = total number of class instances.\n",
    "                    likelihood_attribute = defaultdict(lambda: np.log(smoothingparameter)\\\n",
    "                                                       -np.log(class_data.shape[0]+ smoothingparameter*numUniqueValues))\n",
    "               \n",
    "                    # Calculate relative frequency as an estimate to the likelihood\n",
    "                    for unique_value in class_data[attribute].unique():\n",
    "                        likelihood_attribute[unique_value] = np.log(sum(class_data[attribute] == unique_value)+smoothingparameter)\\\n",
    "                        -np.log(class_data.shape[0] + smoothingparameter* numUniqueValues)\n",
    "                    \n",
    "                Model[classlabel]['likelihood'][attribute] = likelihood_attribute\n",
    "                \n",
    "    return Model\n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_val_train(cross_val_dict):\n",
    "    \n",
    "    '''\n",
    "    Trains cross-validation training set\n",
    "    \n",
    "    Returns modelCV, a list of dictionaries containing all necessary values for Naive Bayes Classifier\n",
    "    '''\n",
    "    \n",
    "    #modelCV = [{}, {}, {}...]\n",
    "    modelCV = []\n",
    "    \n",
    "    #training_set should contain 10 partitions\n",
    "    training_set = cross_val_dict['training']\n",
    "    \n",
    "    # Train each partition\n",
    "    # Append Rule of each partition to modelCV\n",
    "    for i in range(len(training_set)):\n",
    "        \n",
    "        # Smoothing\n",
    "        smoothparam = 0\n",
    "        num_unique = {}\n",
    "        for f in (training_set[i]):\n",
    "            num_unique[f] = len(training_set[i][f].unique()) # not what i intended\n",
    "        \n",
    "        modelCV.append(train(training_set[i], (num_unique, smoothparam)))\n",
    "        \n",
    "    return modelCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function should predict classes for new items in a test dataset (for the purposes of this assignment, you \n",
    "# can re-use the training data as a test set)\n",
    "\n",
    "def predict(testset, Model):\n",
    "    '''\n",
    "    Produces a list of predicted class labels from a naive-bayes classifier.\n",
    "    Model: dictionary of priors and likelihoods\n",
    "    returns: list of class labels\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    # Contains predicted classes for testset instances\n",
    "    predictions = []\n",
    "    \n",
    "    # For each instance, try to predict what the class label should be\n",
    "    for rowindex in range(testset.shape[0]):\n",
    "        \n",
    "        posteriors = {}\n",
    "        \n",
    "        # Find the posterior probability for each class: product of prior and likelihoods = sum of all log probabilities\n",
    "        for classlabel in Model:\n",
    "            \n",
    "            # Log Prior\n",
    "            posteriors[classlabel] = Model[classlabel]['prior']\n",
    "            \n",
    "            # Sum of log likelihoods\n",
    "            for attribute in Model[classlabel]['likelihood']:\n",
    "\n",
    "                # If missing, exclude from calculation.\n",
    "                # Equivalent to multiplying by one, but no effect as it affects all posterior probabilities\n",
    "                if testset.iloc[rowindex,:][attribute] == np.NaN:\n",
    "                    print('missing value identified') # should print once for each class\n",
    "                    \n",
    "                \n",
    "                # If numeric data, calculate log likelihood from pdf and add\n",
    "                elif isNumericAttribute(testset[attribute]):\n",
    "                    \n",
    "                    mu, sig = Model[classlabel]['likelihood'][attribute]\n",
    "                    \n",
    "                    # Gaussian probability distribution\n",
    "                    posteriors[classlabel] += np.log(stats.norm.pdf(testset.iloc[rowindex,:][attribute],\n",
    "                                                                    loc = mu, scale = sig))\n",
    "              \n",
    "                # If relative frequency: search for log likelihood and add\n",
    "                else:\n",
    "                    posteriors[classlabel] += Model[classlabel]['likelihood'][attribute][testset.iloc[rowindex,:][attribute]]\n",
    "\n",
    "        # Select greatest posterior probability\n",
    "        predictedclass = None\n",
    "        \n",
    "        for classlabel in posteriors:\n",
    "            if (predictedclass == None) or (posteriors[classlabel] > posteriors[predictedclass]):\n",
    "                predictedclass = classlabel\n",
    "        \n",
    "        # Add prediction of an instance to the set of prediction\n",
    "        predictions.append(predictedclass)\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_val_predict(cross_val_dict, modelCV):    \n",
    "    '''Returns predictions for cross-validation'''\n",
    "    \n",
    "    testing_set = cross_val_dict['testing']\n",
    "    \n",
    "    # predictionsCV = []\n",
    "    predictionsCV = []\n",
    "    \n",
    "    for i in range(len(testing_set)):\n",
    "        predictionsCV.append(predict(testing_set[i], modelCV[i]))\n",
    "        \n",
    "    return predictionsCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function should evaliate the prediction performance by comparing your model’s class outputs to ground truth labels\n",
    "\n",
    "def evaluate(groundtruth, predictedlabels):\n",
    "    '''\n",
    "    groundtruth: array of true class labels for a dataset \n",
    "    predicted: array of predicted class labels predicted by the NaiveBayes model\n",
    "    \n",
    "    Returns: accuracy, and a confusion matrix in a tuple\n",
    "    '''\n",
    "    \n",
    "    # Verify that the number of predictions matches the size of the test set\n",
    "    assert(len(groundtruth) == len(predictedlabels))\n",
    "    \n",
    "    # Elementwise comparison to find matches (True) and sum to get total number of matches\n",
    "    correct = 0\n",
    "    for i in range(len(groundtruth)):\n",
    "        correct += (groundtruth[i] == predictedlabels[i])\n",
    "    \n",
    "    confusion = pd.DataFrame({'groundtruth': groundtruth, 'predicted': predictedlabels})\n",
    "    \n",
    "    confusion = pd.crosstab(confusion['groundtruth'], confusion['predicted'], \n",
    "                            rownames=['groundtruth'], colnames = ['predicted'])\n",
    "    \n",
    "    #return accuracy and confusion matrix\n",
    "    return correct/len(predictedlabels), confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_val_evaluate(cross_val_dict, predictionsCV):\n",
    "    \n",
    "    '''\n",
    "    Compares cross validation testing set labels (groundtruth)\n",
    "    \n",
    "    to predicted labels of cross validation\n",
    "    \n",
    "    Returns: a list of accuracies \n",
    "    '''\n",
    "    \n",
    "    #list to store cross validation accuracies\n",
    "    # accuraciesCV = [0.99, 0.98, ....]\n",
    "    accuraciesCV = []\n",
    "    \n",
    "    testing_set = cross_val_dict['testing']\n",
    "    \n",
    "    # Extract actual class labels (cross val groundtruth) from testing set\n",
    "    # groundtruthsCV = [[groundtruth from 1st testing set], [groundtruth from 2nd testing set],...]\n",
    "    \n",
    "    groundtruthsCV = []\n",
    "    for i in range(len(testing_set)):\n",
    "        \n",
    "        groundtruth = cross_val_dict['testing'][i]['class']\n",
    "        groundtruth_list = groundtruth.tolist()\n",
    "        groundtruthsCV.append(groundtruth_list)        \n",
    "        \n",
    "    # Appends accuracies to accuraciesCV\n",
    "    for i in range(len(groundtruthsCV)):\n",
    "        accuracy = evaluate(groundtruthsCV[i], predictionsCV[i])\n",
    "        accuraciesCV.append(accuracy[0])\n",
    "    \n",
    "    #return mean of accuraciesCV\n",
    "    return np.mean(accuraciesCV)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions \n",
    "\n",
    "\n",
    "If you are in a group of 1, you will respond to question (1), and **one** other of your choosing (two responses in total).\n",
    "\n",
    "If you are in a group of 2, you will respond to question (1) and question (2), and **two** others of your choosing (four responses in total). \n",
    "\n",
    "A response to a question should take about 100–250 words, and make reference to the data wherever possible.\n",
    "\n",
    "#### NOTE: you may develope codes or functions in respond to the question, but your formal answer should be added to a separate file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q1\n",
    "Try discretising the numeric attributes in these datasets and treating them as discrete variables in the na¨ıve Bayes classifier. You can use a discretisation method of your choice and group the numeric values into any number of levels (but around 3 to 5 levels would probably be a good starting point). Does discretizing the variables improve classification performance, compared to the Gaussian na¨ıve Bayes approach? Why or why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code Instructions for Q1\n",
    "\n",
    "Define the functions. The discretize function may be customized to achieve equal-size or equal-frequency binning.\n",
    "\n",
    "In the main code:\n",
    "\n",
    "* Select the dataset to be used in the naive-bayes model.\n",
    "* By default, the model will use Gaussian NB unless the discretize function is used. The number of bins can be varied by the user.\n",
    "* If smoothing is desired (not used in Q1), the smoothing parameter can be changed. Only relevant for discretized numerical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isNumericAttribute(series):\n",
    "    ''' \n",
    "    Datasets: wine, wdbc, bank\n",
    "    \n",
    "    Ensures that the train function uses the Gaussian pdf.\n",
    "    \n",
    "    Returns True if the series contains a numeric attribute, and false otherwise.\n",
    "    '''\n",
    "    if series.dtype == object:\n",
    "        return False\n",
    "    if len(series.unique())>9:\n",
    "        #print(series.name, 'is numeric')\n",
    "        return True\n",
    "\n",
    "    return False\n",
    "\n",
    "def discretize(data, bins = 5):\n",
    "    '''\n",
    "    Datasets: wine, wdbc, bank\n",
    "    \n",
    "    Assumes data is a dataFrame of features only\n",
    "    Discretizes only the numeric attributes, which are determined by number of unique values.\n",
    "    \n",
    "    Returns: the same dataframe with numeric features in equal-sized bins\n",
    "    '''\n",
    "    \n",
    "    discretizeddata = data\n",
    "    for feature in data.columns:\n",
    "        if isNumericAttribute(data[feature]):\n",
    "            # create bins and group\n",
    "            \n",
    "            # Equal-size bins\n",
    "            discretizeddata[feature]= pd.qcut(discretizeddata[feature], bins, duplicates = 'drop')\n",
    "            \n",
    "            # Equal-width bins\n",
    "            #discretizeddata[feature]= pd.cut(discretizeddata[feature], bins, duplicates = 'drop')\n",
    "            \n",
    "            print(feature, 'was discretized')\n",
    "    \n",
    "    return discretizeddata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'preprocess' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-706b99b45209>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;31m#dataset = preprocess('bank.data')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpreprocess\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'wine.data'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[1;31m#dataset = preprocess('wdbc.data')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'preprocess' is not defined"
     ]
    }
   ],
   "source": [
    "for bins in [0,3,5]: # Include 0 at the front of the list to include GaussianNB\n",
    "\n",
    "    # Uncomment to select a dataset\n",
    "\n",
    "    #dataset = preprocess('bank.data')\n",
    "    dataset = preprocess('wine.data')\n",
    "    #dataset = preprocess('wdbc.data')\n",
    "\n",
    "    # Check if GaussianNB is required (needs to be first or the data will already be discretized)\n",
    "    if bins != 0:\n",
    "        # === Discretize ===\n",
    "        print(dataset.head(1))\n",
    "        dataset = discretize(dataset, bins)\n",
    "        # ==================\n",
    "\n",
    "    print('shape:', dataset.shape)\n",
    "\n",
    "    # Verify that all features are correctly formatted\n",
    "    print(dataset.head(1))\n",
    "\n",
    "    for iteration in range(1000,1003): # Seed\n",
    "\n",
    "        results = []\n",
    "        split = 0.5\n",
    "\n",
    "        random.seed(iteration)\n",
    "        indices = [x for x in range(0,dataset.shape[0])]\n",
    "        random.shuffle(indices)\n",
    "\n",
    "        trainingindex = indices[0:int(dataset.shape[0]*split)]        \n",
    "        testindex = indices[int(dataset.shape[0]*split):dataset.shape[0]]\n",
    "\n",
    "        trainingset = dataset.iloc[trainingindex,:]\n",
    "        testset = dataset.iloc[testindex,:]\n",
    "\n",
    "        groundtruth_in = trainingset['class']\n",
    "        groundtruth_out = testset['class']\n",
    "\n",
    "        trainingset_noclass = trainingset.drop('class', axis=1)\n",
    "        testset_noclass = testset.drop('class', axis=1)\n",
    "\n",
    "        # Smoothing\n",
    "        smoothparam = 0\n",
    "        num_unique = {}\n",
    "        for f in dataset:\n",
    "            num_unique[f] = len(dataset[f].unique())\n",
    "\n",
    "        # Naive-Bayes Model: No Smoothing\n",
    "        modelNB_nosmooth = train(trainingset.dropna(), (num_unique, smoothparam))\n",
    "\n",
    "        trainingfitNB_nosmooth = predict(trainingset_noclass, modelNB_nosmooth)\n",
    "        trainingevaluationNB_nosmooth = evaluate(groundtruth_in.tolist(), trainingfitNB_nosmooth)\n",
    "\n",
    "        predictionNB_nosmooth = predict(testset_noclass, modelNB_nosmooth)\n",
    "        evaluationNB_nosmooth = evaluate(groundtruth_out.tolist(), predictionNB_nosmooth)\n",
    "\n",
    "        # Print results\n",
    "        print('===================================')\n",
    "        print('No Smoothing, bins:', bins)\n",
    "        print('In-sample accuracy:', round(trainingevaluationNB_nosmooth[0],4))\n",
    "        print('Out-of-sample accuracy:', round(evaluationNB_nosmooth[0],4))\n",
    "        print(evaluationNB_nosmooth[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q2\n",
    "Implement a baseline model (e.g., random or 0R) and compare the performance of the na¨ıve Bayes classifier to this baseline on multiple datasets. Discuss why the baseline performance varies across datasets, and to what extent the na¨ıve Bayes classifier improves on the baseline performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2 Instructions:\n",
    "* Run the isNumericAttribute and baseline functions.\n",
    "* Run the main code. Edit the code to customize: dataset, smoothing parameter.\n",
    "\n",
    "In the assignment, no smoothing was used for this question, and the entire dataset was used in training and testing (instances with missing values were removed during training)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isNumericAttribute(series):\n",
    "    ''' \n",
    "    Datasets: wine, wdbc, bank\n",
    "    \n",
    "    Ensures that the train function uses the Gaussian pdf.\n",
    "    \n",
    "    Returns True if the series contains a numeric attribute, and false otherwise.\n",
    "    '''\n",
    "    if series.dtype == object:\n",
    "        return False\n",
    "    if len(series.unique())>9:\n",
    "        #print(series.name, 'is numeric')\n",
    "        return True\n",
    "\n",
    "    return False\n",
    "\n",
    "def discretize(data, bins = 5):\n",
    "    '''\n",
    "    Datasets: wine, wdbc, bank\n",
    "    \n",
    "    Assumes data is a dataFrame of features only\n",
    "    Discretizes only the numeric attributes, which are determined by number of unique values.\n",
    "    \n",
    "    Returns: the same dataframe with numeric features in equal-sized bins\n",
    "    '''\n",
    "    \n",
    "    discretizeddata = data\n",
    "    for feature in data.columns:\n",
    "        if isNumericAttribute(data[feature]):\n",
    "            # create bins and group\n",
    "            \n",
    "            # Uncomment to select: equal-size bins\n",
    "            discretizeddata[feature]= pd.qcut(discretizeddata[feature], bins, duplicates = 'drop')\n",
    "            \n",
    "            # Uncomment to select: Equal-width bins\n",
    "            #discretizeddata[feature]= pd.cut(discretizeddata[feature], bins, duplicates = 'drop')\n",
    "            \n",
    "            print(feature, 'was discretized')\n",
    "    \n",
    "    return discretizeddata\n",
    "\n",
    "def baseline_train(data):\n",
    "    ''' Returns the class which appears the most frequently in the training set'''\n",
    "    maxclass = data['class'].value_counts().idxmax()\n",
    "    return maxclass\n",
    "\n",
    "def baseline_predict(data, maxclass):\n",
    "    ''' Returns the predicted labels on a testset given a baseline model'''\n",
    "    return [maxclass for x in range(data.shape[0])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'preprocess' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-0cec8394eca7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Uncomment to select a datasetset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m#dataset = preprocess('wine.data')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpreprocess\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'wdbc.data'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;31m#dataset = preprocess('bank.data')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'preprocess' is not defined"
     ]
    }
   ],
   "source": [
    "# Uncomment to select a datasetset\n",
    "#dataset = preprocess('wine.data')\n",
    "dataset = preprocess('wdbc.data')\n",
    "#dataset = preprocess('bank.data')\n",
    "\n",
    "print('shape:', dataset.shape)\n",
    "print(dataset.head(1))\n",
    "\n",
    "results = []\n",
    "\n",
    "groundtruth = dataset['class']\n",
    "dataset_noclass = dataset.drop('class', axis=1)\n",
    "\n",
    "# Baseline model: 0R\n",
    "modelBaseline = baseline_train(dataset)\n",
    "predictionBaseline = baseline_predict(dataset.dropna(), modelBaseline)\n",
    "evaluationBaseline = evaluate(groundtruth, predictionBaseline)\n",
    "\n",
    "# Smoothing\n",
    "smoothparam = 0\n",
    "num_unique = {}\n",
    "for f in dataset:\n",
    "    num_unique[f] = len(dataset[f].unique())\n",
    "\n",
    "# Naive-Bayes Model\n",
    "modelNB = train(dataset.dropna(), (num_unique, smoothparam))\n",
    "predictionNB = predict(dataset_noclass, modelNB)\n",
    "evaluationNB = evaluate(groundtruth, predictionNB)\n",
    "\n",
    "# Print results\n",
    "print('===================================')\n",
    "print('Baseline Accuracy = ', round(evaluationBaseline[0],4))\n",
    "\n",
    "# Smoothed:\n",
    "print('Smoothing parameter = ', smoothparam)\n",
    "print(evaluationBaseline[1])\n",
    "\n",
    "print('===================================')\n",
    "print('NB Accuracy = ', round(evaluationNB[0],4))\n",
    "\n",
    "print(evaluationNB[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q4\n",
    "Evaluating the model on the same data that we use to train the model is considered to be a major mistake in Machine Learning. Implement a hold–out or cross–validation evaluation strategy (you should implement this yourself and do not simply call existing implementations from `scikit-learn`). How does your estimate of effectiveness change, compared to testing on the training data? Explain why. (The result might surprise you!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q4 Instructions:\n",
    "\n",
    "* Nominal datasets(f2,f3) and Numerical datasets (f4,f5) will be used.\n",
    "* Run testing on training and 10-fold cross-validation.\n",
    "* Testing on training accuracy will be printed. \n",
    "* Average accuracy will be printed for 10-fold Cross Validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#################### 10-FOLD CROSS VALIDATION ####################\n",
    "\n",
    "''' Compares accuracies of Testing on Training Data and Cross Validation'''\n",
    "\n",
    "nominal_numerical_datasets = [f2,f3,f4,f5]\n",
    "# Nominal Datasets = f2,f3\n",
    "# Numerical Datasets = f4,f5\n",
    "\n",
    "for data in nominal_numerical_datasets:\n",
    "    print('=' * 50)\n",
    "    print(f\"{data}\")\n",
    "    print('=' * 50)\n",
    "    \n",
    "    #################### TESTING ON TRAINING DATA ####################\n",
    "    dataframe = preprocess(data, cross_validation = False)\n",
    "    \n",
    "    groundtruth = dataframe['class']\n",
    "    data_noclass = dataframe.drop('class', axis=1)\n",
    "    \n",
    "    # Smoothing\n",
    "    smoothparam = 0\n",
    "    num_unique = {}\n",
    "    for f in dataframe:\n",
    "        num_unique[f] = len(dataframe[f].unique())\n",
    "\n",
    "\n",
    "    # Naive-Bayes Model\n",
    "    modelNB = train(dataframe.dropna(), (num_unique, smoothparam))\n",
    "    predictionNB = predict(data_noclass, modelNB)\n",
    "    evaluationNB = evaluate(groundtruth, predictionNB)\n",
    "    print('Testing on Training Data Accuracy = ', round(evaluationNB[0],4))\n",
    "    \n",
    "    # 10-fold Cross Validation\n",
    "    cross_val_dict = preprocess(data, cross_validation = True)\n",
    "    modelCV = cross_val_train(cross_val_dict)\n",
    "    predictionsCV = cross_val_predict(cross_val_dict, modelCV)\n",
    "    evaluationCV = cross_val_evaluate(cross_val_dict, predictionsCV)\n",
    "    print('Cross Validation Accuracy Average= ', round(evaluationCV, 4))\n",
    "    print('=' * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q5\n",
    "Implement one of the advanced smoothing regimes (add-k, Good-Turing). Does changing the smoothing regime (or indeed, not smoothing at all) affect the effectiveness of the na¨ıve Bayes classifier? Explain why, or why not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q5 Instructions:\n",
    "* Run the isNumericAttribute Function to ensure that all attributes are read as nominal data.\n",
    "* Run the main code. Edit the code to customize: dataset, random seed, dataset split, smoothing parameter.\n",
    "    \n",
    "In the assignment, the data was split 50/50, the random seeds used were 1000 to 1002, and the smoothing parameters used were 0,1 and 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isNumericAttribute(series):\n",
    "    '''\n",
    "    Datasets: breast_cancer_wisconsin, lymphography (all features assumed to be Nominal)\n",
    "    \n",
    "    Returns True if the series contains a numeric attribute, and false otherwise.\n",
    "    '''\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 missing values found.\n",
      "shape: (148, 19)\n",
      "   class  lymphatics  block of affere  bl. of lymph. c  bl. of lymph. s  \\\n",
      "0      3           4                2                1                1   \n",
      "\n",
      "   by pass  extravasates  regeneration of  early uptake in  lym.nodes dimin  \\\n",
      "0        1             1                1                2                1   \n",
      "\n",
      "   lym.nodes enlar  changes in lym.  defect in node  changes in node  \\\n",
      "0                2                2               2                4   \n",
      "\n",
      "   changes in stru  special forms  dislocation of  exclusion of no  \\\n",
      "0                8              1               1                2   \n",
      "\n",
      "   no. of nodes in  \n",
      "0                2  \n",
      "===================================\n",
      "No Smoothing:\n",
      "In-sample accuracy: 0.8649\n",
      "Out-of-sample accuracy: 0.8378\n",
      "predicted     2   3  4\n",
      "groundtruth           \n",
      "1             0   1  0\n",
      "2            35   3  0\n",
      "3             8  26  0\n",
      "4             0   0  1\n",
      "======\n",
      "Smoothing parameter =  1\n",
      "In-sample accuracy: 0.8649\n",
      "Out-of-sample accuracy: 0.8514\n",
      "predicted     2   3  4\n",
      "groundtruth           \n",
      "1             1   0  0\n",
      "2            36   2  0\n",
      "3             8  26  0\n",
      "4             0   0  1\n",
      "===================================\n",
      "No Smoothing:\n",
      "In-sample accuracy: 0.9459\n",
      "Out-of-sample accuracy: 0.7297\n",
      "predicted     2   3\n",
      "groundtruth        \n",
      "1             2   0\n",
      "2            36   5\n",
      "3            11  18\n",
      "4             0   2\n",
      "======\n",
      "Smoothing parameter =  1\n",
      "In-sample accuracy: 0.9324\n",
      "Out-of-sample accuracy: 0.7568\n",
      "predicted     2   3  4\n",
      "groundtruth           \n",
      "1             2   0  0\n",
      "2            39   2  0\n",
      "3            13  16  0\n",
      "4             1   0  1\n",
      "===================================\n",
      "No Smoothing:\n",
      "In-sample accuracy: 0.9189\n",
      "Out-of-sample accuracy: 0.7432\n",
      "predicted     2   3\n",
      "groundtruth        \n",
      "1             1   0\n",
      "2            33  10\n",
      "3             5  22\n",
      "4             0   3\n",
      "======\n",
      "Smoothing parameter =  1\n",
      "In-sample accuracy: 0.9189\n",
      "Out-of-sample accuracy: 0.8108\n",
      "predicted     2   3  4\n",
      "groundtruth           \n",
      "1             0   1  0\n",
      "2            39   4  0\n",
      "3             7  20  0\n",
      "4             0   2  1\n"
     ]
    }
   ],
   "source": [
    "# Uncomment to select a dataset\n",
    "#dataset = preprocess('breast-cancer-wisconsin.data')\n",
    "dataset = preprocess('lymphography.data')\n",
    "\n",
    "print('shape:', dataset.shape)\n",
    "\n",
    "# Verify that all features are correctly formatted\n",
    "print(dataset.head(1))\n",
    "\n",
    "for iteration in range(1000,1003):\n",
    "\n",
    "    results = []\n",
    "    split = 0.5\n",
    "\n",
    "    random.seed(iteration)\n",
    "    indices = [x for x in range(0,dataset.shape[0])]\n",
    "    random.shuffle(indices)\n",
    "\n",
    "    trainingindex = indices[0:int(dataset.shape[0]*split)]        \n",
    "    testindex = indices[int(dataset.shape[0]*split):dataset.shape[0]]\n",
    "\n",
    "    trainingset = dataset.iloc[trainingindex,:]\n",
    "    testset = dataset.iloc[testindex,:]\n",
    "\n",
    "    groundtruth_in = trainingset['class']\n",
    "    groundtruth_out = testset['class']\n",
    "    \n",
    "    trainingset_noclass = trainingset.drop('class', axis=1)\n",
    "    testset_noclass = testset.drop('class', axis=1)\n",
    "\n",
    "    # Smoothing\n",
    "    smoothparam = 0\n",
    "    num_unique = {}\n",
    "    for f in dataset:\n",
    "        num_unique[f] = len(dataset[f].unique())\n",
    "\n",
    "    # Naive-Bayes Model: No Smoothing\n",
    "    modelNB_nosmooth = train(trainingset.dropna(), (num_unique, smoothparam))\n",
    "    \n",
    "    trainingfitNB_nosmooth = predict(trainingset_noclass, modelNB_nosmooth)\n",
    "    trainingevaluationNB_nosmooth = evaluate(groundtruth_in.tolist(), trainingfitNB_nosmooth)\n",
    "    \n",
    "    predictionNB_nosmooth = predict(testset_noclass, modelNB_nosmooth)\n",
    "    evaluationNB_nosmooth = evaluate(groundtruth_out.tolist(), predictionNB_nosmooth)\n",
    "\n",
    "    # Naive-Bayes Model: Smoothing with k=1\n",
    "    smoothparam1 = 1 # Change smoothing parameter here\n",
    "    \n",
    "    modelNB_smooth1 = train(trainingset.dropna(), (num_unique, smoothparam1))\n",
    "    \n",
    "    trainingfitNB_smooth1 = predict(trainingset_noclass, modelNB_smooth1)\n",
    "    trainingevaluationNB_smooth1 = evaluate(groundtruth_in.tolist(), trainingfitNB_smooth1)\n",
    "    \n",
    "    predictionNB_smooth1 = predict(testset_noclass, modelNB_smooth1)\n",
    "    evaluationNB_smooth1 = evaluate(groundtruth_out.tolist(), predictionNB_smooth1)\n",
    "    \n",
    "    # Naive-Bayes Model: Smoothing with k=5\n",
    "    smoothparam5 = 5 # Change smoothing parameter here\n",
    "    \n",
    "    modelNB_smooth5 = train(trainingset.dropna(), (num_unique, smoothparam5))\n",
    "    \n",
    "    trainingfitNB_smooth5 = predict(trainingset_noclass, modelNB_smooth)\n",
    "    trainingevaluationNB_smooth5 = evaluate(groundtruth_in.tolist(), trainingfitNB_smooth5)\n",
    "    \n",
    "    predictionNB_smooth5 = predict(testset_noclass, modelNB_smooth5)\n",
    "    evaluationNB_smooth5 = evaluate(groundtruth_out.tolist(), predictionNB_smooth5)\n",
    "\n",
    "    # Print results\n",
    "    print('===================================')\n",
    "    print('No Smoothing:')\n",
    "    print('In-sample accuracy:', round(trainingevaluationNB_nosmooth[0],4))\n",
    "    print('Out-of-sample accuracy:', round(evaluationNB_nosmooth[0],4))\n",
    "    print(evaluationNB_nosmooth[1])\n",
    "\n",
    "    print('======')\n",
    "    print('Smoothing parameter = ', smoothparam1)\n",
    "    print('In-sample accuracy:', round(trainingevaluationNB_smooth1[0],4))\n",
    "    print('Out-of-sample accuracy:', round(evaluationNB_smooth1[0],4))\n",
    "    print(evaluationNB_smooth1[1])\n",
    "    \n",
    "    print('======')\n",
    "    print('Smoothing parameter = ', smoothparam5)\n",
    "    print('In-sample accuracy:', round(trainingevaluationNB_smooth5[0],4))\n",
    "    print('Out-of-sample accuracy:', round(evaluationNB_smooth5[0],4))\n",
    "    print(evaluationNB_smooth5[1])\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
